---
title: "DEM 5093/7093 - Mapping Using the American Community Survey - Change Mapping"
author: "Corey Sparks, Ph.D."
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
   html_document:
   toc: yes
   toc_float: yes
always_allow_html: yes
download_code: yes
---

This example will use R to download American Community Survey summary file tables using the `tidycensus` package. The goal of this example is to illustrate how to download data from the Census API using R, how to create basic descriptive maps of attributes and how to construct a change map between two time periods. 

The example will use data from San Antonio, Texas from the American Community Survey summary file.

### Get a Census developer API Key
Obtain one at http://api.census.gov/data/key_signup.html

### Save your API key to your working directory
use `census_api_key(key =  "yourkeyhere", install = T)`

one time to install your key for use in `tidycensus`

### Load Libraries
```{r}
library(tidycensus)
library(tidyverse)
library(sf)
library(tmap)

```

You should *always* check the variable name of your ACS variable, you *cannot assume* that the variable name stays the same across years.

```{r}
v10_Profile <- load_variables(2010,
                              "acs5/profile",
                              cache = TRUE) #demographic profile tables
v19_Profile <- load_variables(2019,
                              "acs5/profile",
                              cache = TRUE) #demographic 

#Search for variables by using grep()

v10_Profile[grep(x = v10_Profile$label,
                 "BELOW THE POVERTY LEVEL",
                 ignore.case = TRUE), 
            c("name", "label")]

v19_Profile[grep(x = v19_Profile$label,
                 "BELOW THE POVERTY LEVEL",
                 ignore.case = TRUE),
            c("name", "label")]
```

## Extract from ACS summary file data profile variables from 2010 and 2019 for Bexar County, TX Census Tracts

The data profile tables are very useful because they contain lots of pre-calculated variables.

```{r, results='hide'}
pov10<-get_acs(geography = "tract",
                state="TX",
                county = "Bexar",
                year = 2010,
                variables="DP03_0119P" ,
                geometry = T,
                output = "wide")


#rename variables and filter missing cases
pov10 <- pov10%>%
  mutate(ppov = DP03_0119PE,
         ppov_er = DP03_0119PM/1.645,
         ppov_cv =100* (ppov_er/ppov)) %>%
  filter(complete.cases(ppov), is.finite(ppov_cv)==T)%>%
  select(GEOID, ppov, ppov_er,ppov_cv)

head(pov10)

```

## Alternative break strategies

Two common ways to break a continuous variable into discrete bins are quantile breaks and Jenks/Fisher breaks.

```{r}


tm_shape(pov10)+
  tm_polygons(c("ppov"),
              title=c("% in Poverty"),
              palette="Blues",
              style="quantile",
              n=5)+
  #tm_format("World", legend.outside=T, title.size =4)+
  tm_scale_bar()+
  tm_layout(title="San Antonio Poverty Rate Estimates - Quantile Breaks",
            title.size =1.5,
            legend.frame = TRUE,
            title.position = c('right', 'top'))+
  tm_compass()+
  tm_format("World",
            legend.position =  c("left", "bottom"),
            main.title.position =c("center"))

tm_shape(pov10)+
  tm_polygons(c("ppov"),
              title=c("% in Poverty"),
              palette="Blues",
              style="jenks",
              n=5)+
  #tm_format("World", legend.outside=T, title.size =4)+
  tm_scale_bar()+
  tm_layout(title="San Antonio Poverty Rate Estimates - Jenks Breaks",
            title.size =1.5,
            legend.frame = TRUE,
            title.position = c('right', 'top'))+
  tm_compass()+
  tm_format("World",
            legend.position =  c("left", "bottom"),
            main.title.position =c("center"))


```


## Mapping of errors in estimates

Here I generate a quantile break for the *coefficient of variation* in census tract poverty estimates.

If you don't remember, the coefficient of variation is:

$$CV =\frac {\sigma }{\mu}$$

and is a measure of the variability in the estimate, relative to the estimate itself. If the CV is greater than 100, the estimate is very imprecise. The lower the value, the more precise the estimate. This is very important when using small area estimates from the ACS. 

When presenting data from the ACS, you should always examine the coefficients of variation, as the ACS is based off a survey, and the estimates, especially for small or rare groups can be very imprecise.

```{r}


p1<-tm_shape(pov10)+
  tm_polygons(c("ppov"),
              title=c("% in Poverty"),
              palette="Blues",
              style="quantile",
              n=5)+
  #tm_format("World", legend.outside=T, title.size =4)+
  tm_scale_bar()+
  tm_layout(title="San Antonio Poverty Rate Estimates",
            title.size =1.5, 
            legend.frame = TRUE,
            title.position = c('right', 'top'))+
  tm_compass()+
  tm_format("World",
            legend.position =  c("left", "bottom"),
            main.title.position =c("center"))


p2<-tm_shape(pov10)+
  tm_polygons(c("ppov_cv"),
              title=c("CV Poverty"),
              palette="Blues",
              style="quantile",
              n=5)+
  #tm_format("World", title="San Antonio Poverty Rate CV", legend.outside=T)+
  tm_layout(title="San Antonio Poverty Rate CV",
            title.size =1.5,
            legend.frame = TRUE,
            title.position = c('right', 'top'))+
  tm_scale_bar()+
  tm_compass()+
  tm_format("World",
            legend.position =  c("left", "bottom"),
            main.title.position =c("center"))



tmap_arrange(p1, p2)

```

```{r}
plot(pov10$ppov, pov10$ppov_cv, main = "Error in Estimates vs Estimate Size")
```


## Change mapping between two time points
When we have data that are collected over times on the same geographies, we may be interested in whether the variable we're mapping has changed much over time. 

In the ACS, we can compare two estimates if the years used to produce the estimates **do not overlap**. For instance, we could compare the 2006-2010 estimates to the 2015-2019 estimates, but we could **not** compare the 2006-2010 to the 2008-2012, because they share years of data. 

See [this](https://www.census.gov/programs-surveys/acs/guidance/comparing-acs-data.html) for the official position on the subject.

There is a fix that will let us do this. **see below**


## Compare poverty rates over time
Here we take the poverty rate in tracts derived from the 2006-2010 ACS and compare it to the estimate from the 2015-2019 ACS

```{r, results = "hide"}
# get the 2019 estimates
pov19<-get_acs(geography = "tract",
                state="TX",
                county = "Bexar",
                year = 2019,
                variables="DP03_0119P" ,
                geometry = T,
                output = "wide")


#rename variables and filter missing cases
pov19<- pov19%>%
  mutate(ppov19 = DP03_0119PE,
         ppov19_er = DP03_0119PM/1.645,
         ppov19_cv =100* (ppov19_er/ppov19)) %>%
  filter(complete.cases(ppov19), is.finite(ppov19_cv)==T)%>%
  select(GEOID, ppov19, ppov19_er,ppov19_cv)

head(pov19)

```

```{r}

#merge the two years worth of data
st_geometry(pov19)<-NULL #strip the geometry from the 2019 data

mdat<-left_join(pov10, pov19, by=c("GEOID"="GEOID"))

head(mdat)
```


Here I create a function that implements the [testing  procedure](https://www.psc.isr.umich.edu/dis/acs/handouts/Compass_Appendix.pdf) used by the Census for comparing estimates across year. The test for two estimates is:

$$\text{z = }\left| \frac{est_1 - est_2}{(1-C)*\sqrt{se_1^2 + se_2^2}}\right|$$

Where $C$ is the number of years overlap in the estimates.

Here is my function:

```{r}
acstest<-function(names,geoid, est1, err1, est2, err2, alpha, yr1, yr2, span){
  
  se1<-err1/qnorm(.90)
  se2<-err2/qnorm(.90)
  yrs1<-seq(yr1, to=yr1-span)
  yrs2<-seq(yr2, to=yr2-span)

  C<-mean(yrs2%in%yrs1)
  diff<- (est1-est2)
  test<-(est1-est2) / (sqrt(1-C)*sqrt(se1^2+se2^2))
  crit<-qnorm(1-alpha/2)
  pval<-1-pnorm(abs(test))
  result<-NULL
  result[pval > alpha]<-"insignificant change"
  result[pval < alpha & test < 0]<- "significant increase"
  result[pval < alpha & test > 0]<-"significant decrease" 
  
  data.frame(name=names,geoid=geoid, est1=est1, est2=est2, se1=se1, se2=se2,difference=diff, test=test, result=result, pval=pval)
}
```


A very similar function `significance()` from the `tidycensus` package does a similar thing, but with less output.

```{r}
significance(est1=mdat$ppov,
             est2=mdat$ppov19,
             moe1=mdat$ppov_er,
             moe2 = mdat$ppov19_er,
             clevel = .9)
```

```{r}
mdat$signif<- significance(est1=mdat$ppov,
                           est2=mdat$ppov19,
                           moe1=mdat$ppov_er,
                           moe2 = mdat$ppov19_er,
                           clevel = .9)
```


Here I use the function I just made to do the comparisons

```{r}

  diff1019<-acstest(names = mdat$GEOID,
                    geoid = mdat$GEOID,
                    est1 = mdat$ppov,
                    est2 = mdat$ppov19,
                    err1 = mdat$ppov_er,
                    err2=mdat$ppov19_er,
                    alpha = .1,
                    yr1 = 2010, yr2=2019,
                    span = 5)

head(diff1019)
table(diff1019$result)
```

Compare to tidycensus

```{r}
table(mdat$signif) #

```


## Make a map layout

```{r, fig.height=10, fig.width=12}
acs_merge<-left_join(mdat, diff1019, by=c("GEOID"="geoid"))

tmap_mode("plot")
p1<-tm_shape(acs_merge)+
  tm_polygons(c("ppov"),
              title=c("% in Poverty  2010"),
              palette="Blues",
              style="quantile",
              n=5)+
  #tm_format("World", legend.outside=T, title.size =4)+
  tm_scale_bar()+
  tm_layout(title="San Antonio Poverty Rate Estimates 2010",
            title.size =1.5,
            legend.frame = TRUE,
            title.position = c('right', 'top'))+
  tm_compass()+
  tm_format("World",
            legend.position =  c("left", "bottom"),
            main.title.position =c("center"))

p2<-tm_shape(acs_merge)+
  tm_polygons(c("ppov19"),
              title=c("% in Poverty 2019"),
              palette="Blues", 
              style="quantile",
              n=5)+
  #tm_format("World", title="San Antonio Poverty Rate CV", legend.outside=T)+
  tm_layout(title="San Antonio Poverty Rate Estimate 2019",
            title.size =1.5,
            legend.frame = TRUE,
            title.position = c('right', 'top'))+
  tm_scale_bar()+
  tm_compass()+
  tm_format("World",
            legend.position =  c("left", "bottom"),
            main.title.position =c("center"))


p3  <- tm_shape(acs_merge)+
  tm_polygons(c("result"),
              title=c("Changes"),
              palette = "Set2")+
  #tm_format("World", title="San Antonio Poverty Rate CV", legend.outside=T)+
  tm_layout(title="San Antonio Poverty Rate Estimate Changes",
            title.size =1.5, 
            legend.frame = TRUE,
            title.position = c('right', 'top'))+
  tm_scale_bar()+
  tm_compass()
  

tmap_arrange(p1, p2,  p3, nrow=2)

```

## Make an interactive map
```{r}
tmap_mode("view")
#osmtile <- tmaptools::read_osm(pov10, mergeTiles = T)

#tm_shape(osmtile)+
 # tm_rgb()+
tm_shape(acs_merge)+
  tm_polygons("result",
              alpha = .7,
              title=c("Changes"),
              palette = "Set2")+
  #tm_format("World", title="San Antonio Poverty Rate CV", legend.outside=T)+
  tm_layout(title="San Antonio Poverty Rate Estimate Changes",
            title.size =1.5)+
  tm_scale_bar()
  #tm_compass()+
  
```


# Save your data?

`st_write` will save your data so you can import it to QGIS if you want.

```{r}
sf::st_write(acs_merge,
             dsn="../data/lab3_acs.gpkg",
             layer="acs20102019",delete_dsn=T,
             delete_layer=T,
             driver="GPKG") ## Save as geopackage format - QGIS likes this

```

